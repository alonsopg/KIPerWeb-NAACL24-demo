{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84db3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/user/question-retrieval-KIPerWeb/\")\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None) # show full width of showing cols\n",
    "pd.set_option(\"expand_frame_repr\", False) # print cols side by side as it's supposed to be\n",
    "import re\n",
    "import json\n",
    "from ranx import Qrels, evaluate, Run\n",
    "import swifter\n",
    "import json\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2360af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the original pool\n",
    "\n",
    "pool_w_info = pd.read_csv(\"/Users/user/question-retrieval-KIPerWeb/testbeds/queries_experiments/trec_pools/pool_w_metadata.txt\")\n",
    "print(\"original pool\")\n",
    "print(f\"-> Pool size: {pool_w_info.shape[0]}\")\n",
    "# pool_w_info = pool_w_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d86ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get relevance annotations?\n",
    "#     1. translate the query, category and content to a single file for manual validation\n",
    "#     2. Calculate semantic similarity across query/category\n",
    "#     3. Filter only high relevant pairs\n",
    "#     4. Train a FSL method to predict relevance\n",
    "#         1. With the available relevance scores filter only the highest ones\n",
    "#         2. manually create pairs to classify (content, query) -> 0/1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d5076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode all unique utterances for each model\n",
    "def encode_all_utterances(df, models):\n",
    "    unique_texts = pd.concat([df['query'], df['category']]).unique()\n",
    "    encodings = {}\n",
    "    for model in models:\n",
    "        encodings[model] = {text: model.encode(text, convert_to_tensor=True) for text in unique_texts}\n",
    "    return encodings\n",
    "\n",
    "# Function to get average cosine similarity for a single row\n",
    "def get_average_cosine_sim_for_row(row, encodings, models):\n",
    "    total_similarity = 0\n",
    "    for model in models:\n",
    "        encoded_utterance = encodings[model][row['query']]\n",
    "        encoded_q_type = encodings[model][row['category']]\n",
    "        similarity = util.cos_sim(encoded_utterance, encoded_q_type).item()\n",
    "        total_similarity += similarity\n",
    "    return total_similarity / len(models)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# List of pretrained models\n",
    "model_25 =SentenceTransformer(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model_25.tokenizer.pad_token = model_25.tokenizer.eos_token\n",
    "\n",
    "model_2 = SentenceTransformer(\"aari1995/German_Semantic_STS_V2\")\n",
    "# model_2.tokenizer.pad_token = model_2.tokenizer.eos_token\n",
    "\n",
    "\n",
    "models = [\n",
    "SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"),\n",
    "model_2,\n",
    "SentenceTransformer(\"sentence-transformers/LaBSE\"),\n",
    "SentenceTransformer(\"PM-AI/bi-encoder_msmarco_bert-base_german\"),\n",
    "SentenceTransformer(\"efederici/e5-base-multilingual-4096\"),\n",
    "SentenceTransformer(\"intfloat/multilingual-e5-base\"),\n",
    "SentenceTransformer(\"clips/mfaq\"),\n",
    "SentenceTransformer(\"PM-AI/sts_paraphrase_xlm-roberta-base_de-en\"),\n",
    "SentenceTransformer(\"deutsche-telekom/gbert-large-paraphrase-euclidean\"),\n",
    "SentenceTransformer(\"LLukas22/all-MiniLM-L12-v2-embedding-all\"),\n",
    "SentenceTransformer(\"LLukas22/paraphrase-multilingual-mpnet-base-v2-embedding-all\"),\n",
    "SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v1\"),\n",
    "SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\"),\n",
    "SentenceTransformer(\"deutsche-telekom/gbert-large-paraphrase-cosine\"),\n",
    "SentenceTransformer(\"shibing624/text2vec-base-multilingual\"),\n",
    "SentenceTransformer(\"Sahajtomar/German-semantic\"),\n",
    "SentenceTransformer(\"setu4993/LaBSE\"),\n",
    "SentenceTransformer(\"symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\"),\n",
    "SentenceTransformer(\"and-effect/musterdatenkatalog_clf\"),\n",
    "SentenceTransformer(\"nblokker/debatenet-2-cat\"),\n",
    "SentenceTransformer(\"setu4993/LEALLA-large\"),\n",
    "SentenceTransformer(\"dell-research-harvard/lt-wikidata-comp-de\"),\n",
    "SentenceTransformer(\"ef-zulla/e5-multi-sml-torch\"),\n",
    "SentenceTransformer(\"barisaydin/text2vec-base-multilingual\"),\n",
    "model_25\n",
    "]\n",
    "\n",
    "# Example usage\n",
    "# utterance = \"Your test utterance\"\n",
    "# q_type = \"Your query type\"\n",
    "# average_similarity = get_average_cosine_sim(utterance, q_type, models)\n",
    "# print(average_similarity)\n",
    "\n",
    "# Pre-compute all encodings\n",
    "all_encodings = encode_all_utterances(pool_w_info, models)\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "pool_w_info['average_similarity'] = pool_w_info.apply(lambda row: get_average_cosine_sim_for_row(row, all_encodings, models), axis=1)\n",
    "pool_w_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = pool_w_info['average_similarity'].tolist()\n",
    "\n",
    "interval = min(float_list), max(float_list)\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468a74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def categorize_similarity(row):\n",
    "    if 0 <= row['average_similarity'] < 0.60:\n",
    "        return 0\n",
    "    elif 0.60 <= row['average_similarity'] < 0.70:\n",
    "        return 1\n",
    "    elif 0.70 <= row['average_similarity'] <= 1.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return None  # For values outside the specified range\n",
    "\n",
    "# Apply the function to create the new column\n",
    "pool_w_info['qrel'] = pool_w_info.apply(categorize_similarity, axis=1)\n",
    "# pool_w_info['qrel'] = pool_w_info['qrel'].astype(int)\n",
    "pool_w_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_w_info['qrel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_w_info.to_csv(\"/Users/user/question-retrieval-KIPerWeb/testbeds/queries_experiments/trec_pools/testbed.csv\", index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
